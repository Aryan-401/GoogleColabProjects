{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aryan401/vgg16-fruits?scriptVersionId=142069857\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch import nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.utils.data.dataloader import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom time import time\nfrom statistics import mean","metadata":{"execution":{"iopub.status.busy":"2023-09-04T06:43:44.599867Z","iopub.execute_input":"2023-09-04T06:43:44.600215Z","iopub.status.idle":"2023-09-04T06:43:48.550017Z","shell.execute_reply.started":"2023-09-04T06:43:44.600185Z","shell.execute_reply":"2023-09-04T06:43:48.54903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tranform = transforms.Compose([\n    transforms.Resize((224,224)), \n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\ntrain_dataset = torchvision.datasets.ImageFolder(root='../input/fruits/fruits-360_dataset/fruits-360/Training', transform=tranform)\ntest_dataset = torchvision.datasets.ImageFolder(root='../input/fruits/fruits-360_dataset/fruits-360/Test', transform=tranform)\nval_size = int(0.1 * len(train_dataset))\ntrain_size = len(train_dataset) - val_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(\n    train_dataset,\n    [train_size, val_size]\n)\ntrain_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nvalid_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\nprint('Train DataSet len:',len(train_dataset))\nprint('Valid DataSet len:',len(val_dataset))\nprint('Test DataSet len:',len(test_dataset))\nprint('Total DataSet Classes:',len(test_dataset.classes))","metadata":{"execution":{"iopub.status.busy":"2023-09-04T06:43:50.889761Z","iopub.execute_input":"2023-09-04T06:43:50.890315Z","iopub.status.idle":"2023-09-04T06:44:03.965736Z","shell.execute_reply.started":"2023-09-04T06:43:50.890276Z","shell.execute_reply":"2023-09-04T06:44:03.964537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VGG16(nn.Module):\n    def __init__(self):\n        super(VGG16, self).__init__()\n        self.ConvSet_1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.ConvSet_2 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.ConvSet_3 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.ConvSet_4 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.ConvSet_5 = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.FC_Layers = nn.Sequential(\n            nn.Linear(25088, 4096),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(4096, 131),\n        )\n        \n    def forward(self, x):\n        out = self.ConvSet_1(x)\n        out = self.ConvSet_2(out)\n        out = self.ConvSet_3(out)\n        out = self.ConvSet_4(out)\n        out = self.ConvSet_5(out)\n        out = out.reshape(out.shape[0], -1)\n        out = self.FC_Layers(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-09-04T06:44:12.29012Z","iopub.execute_input":"2023-09-04T06:44:12.290474Z","iopub.status.idle":"2023-09-04T06:44:12.311251Z","shell.execute_reply.started":"2023-09-04T06:44:12.290438Z","shell.execute_reply":"2023-09-04T06:44:12.310184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = VGG16()\nmodel = model.to(device=device)\nprint(model)\nprint('Device: ',device)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T08:47:22.825625Z","iopub.execute_input":"2023-09-04T08:47:22.826619Z","iopub.status.idle":"2023-09-04T08:47:24.047362Z","shell.execute_reply.started":"2023-09-04T08:47:22.826572Z","shell.execute_reply":"2023-09-04T08:47:24.046297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1e-4\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr= learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T08:47:49.881004Z","iopub.execute_input":"2023-09-04T08:47:49.881371Z","iopub.status.idle":"2023-09-04T08:47:49.888107Z","shell.execute_reply.started":"2023-09-04T08:47:49.88134Z","shell.execute_reply":"2023-09-04T08:47:49.887029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10 \nprint(f\"Train DataLoader Size: {len(train_dataloader)}\")\nprint(f\"Valid DataLoader Size: {len(valid_dataloader)}\")\nfor epoch in range(num_epochs):\n    global_time = time()\n    local_time_chg = []\n    loss_ep = 0\n    for images, labels in train_dataloader:\n        local_time = time()\n        images = images.to(device=device)\n        labels = labels.to(device=device) \n        optimizer.zero_grad()\n        scores = model(images)\n        loss = criterion(scores,labels)\n        loss.backward()\n        optimizer.step()\n        loss_ep += loss.item()\n        local_time_chg.append(time()-local_time)\n        if len(local_time_chg) % 100 == 0:\n            print(f\"Step Verified: {len(local_time_chg)}\")\n        \n    with torch.no_grad():\n        correct = 0\n        total = 0\n        print(\"Starting Validation Test...\")\n        for images, labels in valid_dataloader:\n            images = images.to(device=device)\n            labels = labels.to(device=device) \n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        print(f'Accuracy of the Model on the {len(val_dataset)} Valid Images: {100*(correct /total)} %')\n\n    print (f'Epoch [{epoch+1}/{num_epochs}] | Loss: {round(loss_ep/len(train_dataloader), 5)} | Step Time: {mean(local_time_chg)} | Epoch Time: {time() - global_time}')","metadata":{"execution":{"iopub.status.busy":"2023-09-04T09:45:51.051181Z","iopub.execute_input":"2023-09-04T09:45:51.051549Z","iopub.status.idle":"2023-09-04T09:46:02.051811Z","shell.execute_reply.started":"2023-09-04T09:45:51.051518Z","shell.execute_reply":"2023-09-04T09:46:02.050532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/VGG16_Fruit.pt\")\nmodel = VGG16()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T09:46:07.491324Z","iopub.execute_input":"2023-09-04T09:46:07.492065Z","iopub.status.idle":"2023-09-04T09:46:09.547428Z","shell.execute_reply.started":"2023-09-04T09:46:07.492029Z","shell.execute_reply":"2023-09-04T09:46:09.546424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/working/VGG16_Fruit.pt\"))\nmodel = model.to(device=device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T09:46:46.192475Z","iopub.execute_input":"2023-09-04T09:46:46.193153Z","iopub.status.idle":"2023-09-04T09:46:46.90606Z","shell.execute_reply.started":"2023-09-04T09:46:46.193121Z","shell.execute_reply":"2023-09-04T09:46:46.904947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_dataloader:\n        images = images.to(device=device)\n        labels = labels.to(device=device) \n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    print('Accuracy of the Model on the {} Test Images: {}%'.format(len(test_dataset), 100*correct /total))","metadata":{"execution":{"iopub.status.busy":"2023-09-04T09:46:51.372804Z","iopub.execute_input":"2023-09-04T09:46:51.37316Z","iopub.status.idle":"2023-09-04T09:50:37.692432Z","shell.execute_reply.started":"2023-09-04T09:46:51.37313Z","shell.execute_reply":"2023-09-04T09:50:37.691288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}